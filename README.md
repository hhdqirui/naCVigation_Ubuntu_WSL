# naCVigation

## Proposed Level of Achievement
Apollo 11

## Motivation

To help those visually impaired people to easily access information as they rely mainly on their hearing to obtain information especially when braille is not available. 

Moreover, sometimes textual information is stored inside pictures and thus this information is not easily accessible, so we want to extract out the important information from the pictures and make it accessible for the visually impaired people as well as the non-visually impaired people for their own purposes.

## Aim

We wish to develop a tool using image recognition and text-to-speech tools to help the visually impaired people in their daily life. For the non-visually impaired people, this tool can help in extraction of text from images and make this process more convenient.

## User Stories 

1.	As the user, this application “speaks out” what is written or printed on a picture without me having to look at the picture or poster to know what is written or printed on them.
2.	As the user, this application can help me extract text from the pictures efficiently which can then be stored or be used for other purposes, without me having to type out the whole text.
3.	As the user, the application can translate the text in different languages which allow me to use that in different context. 
4.	As a visually impaired user, the application has a voice control mechanism that allows me to control what functions to use using voice without the need to physically pick the function.

## How are we different from other platforms?

1.	Some translation apps, such as Youdao Dictionary and PowerWord, may have similar functions. For example, they have the options to take pictures or upload photos so as to translate the words in the pictures or photos from one language to another. However, they do not have the option of speaking out as well as lack the voice control mechanism, which is not user-friendly to visually impaired people.
2.	Some websites, such as Baidu may have the ability to extract the text from the photos, but they do not have the features of translating the text and speaking out the text all together.

## Program flow

![Image](https://drive.google.com/open?id=1A17D9IejHANmGrqYLBMWvcKaKoaB3uXJ)

## Features and Timeline

The Application would be able to extract text in pictures or photos and then convert the extracted text to audio which can be heard by visually impaired people. As such, visually impaired people would be able to know the information printed in the pictures or the photos, thus aiding in their daily navigation.

Additionally, for non-visually impaired people, this application can also make extraction of text from pictures or posters more conveniently. Users can use this application to access the text in the pictures or poster without having to personally type out and duplicate the text in the pictures or posters.

Moreover, we add the features of translating the extracted text in different languages so that users with different needs can use them. For example, those who are in a foreign language society or those who are learning multiple languages may find it helpful.

Last but not least, we include the voice control mechanism for visually impaired people to choose what functions or languages they want to use, instead of using fingers and eyes to choose the function or languages.

In conclusion, we hope to build an integrated platform that allows users to use various functions and languages to support their needs.



## Features to be completed by the mid of June: 

The design should be able to analyse images and extract text from the images

## Features to be completed by July: 

The design should be able to convert the extracted text into audio automatically right after the extraction of text from the image is done

## Features to be completed by the mid of July: 
Corporate this developed tool into a website and test it with sufficient data to make sure it works

## Tech Stack 
1.	Python
2.	OpenCV
3.	Tesseract-OCR
4.	HTML/CSS
5.	JavaScript
6.	Node.js

